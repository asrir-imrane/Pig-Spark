# ğŸš€ ExpÃ©rience PageRank Performance on GCP with Pig and PySpark

## ğŸ“ FacultÃ© des Sciences et des Techniques - Nantes UniversitÃ©

---

**Description**: Ce dÃ©pÃ´t fournit des directives Ã©tape par Ã©tape et des scripts pour configurer et exÃ©cuter un cluster Hadoop/Spark sur Google Cloud Platform (GCP). L'objectif principal est d'utiliser Pig et PySpark pour l'implÃ©mentation de PageRank.

### ğŸ“š Gestion des donnÃ©es distribuÃ©es Ã  large Ã©chelle

- **Professeur**: M. MOLLI Pascal  
- **Ã‰tudiants**:
  - ASRIR Imrane
  - JBARI Khaoula
  - AJOUTATE Safae

---

## ğŸ“˜ PageRank - Comparaison entre Pig et PySpark  

**Consigne**: [Consultez les dÃ©tails de la consigne ici](https://madoc.univ-nantes.fr/mod/assign/view.php?id=1523335)


## ğŸ“š Table of Contents
- [**Setting Up on GCP**](./setup/gcp_setup.md)
- [**Hadoop and Spark Installation & Configuration**](./setup/hadoop_spark_setup.md)



## ğŸš€ Running PageRank

### ğŸ– Pig

ğŸ“ **Directory**: `scripts/pig/`   
ğŸ”§ **Command**: Use `run_pagerank.sh` to initiate the PageRank computation.

| Nombre de nÅ“uds | Temps d'exÃ©cution | Dataproc Job ID |
|:---------------:|:-----------------:|:---------------:|
| 2               | 1h 22min          | `8adfa467418740639f80428886007559` |
| 3               | 1h 10min          | `104ad0ee059d84dd7a108cb95c23387e1` |
| 4               | 58min 15s         | `4ecdd4e131e154d38b3e193019ed9cb09` |
| 5               | 51min 13s         | `d273d8af8251a474fa55d3a6cbbb3d87be` |

### ğŸ”¥ PySpark

ğŸ“ **Directory**: `scripts/pyspark/`   
ğŸ”§ **Command**: Use `run.sh` to initiate the PageRank computation.

| Nombre de nÅ“uds | Temps d'exÃ©cution | Dataproc Job ID |
|:---------------:|:-----------------:|:---------------:|
| 2               | 1h 5min           | `d197e9a75eb84e728f168ce07d1b2849` |
| 3               | 54min 8s          | `efb42eb6d08847768a6543a5ee8c7176` |
| 4               | 48min 31s         | `dcc9ddf87ec74685b960af7eef3763ea` |
| 5               | 49min 39s         | `2b2acb5c8bd7c41b4bb50232d9ecc0bd` |

## ğŸ“Š Comparaison entre Pig et PySpark


![Comparaison Pig vs PySpark](./graph/trinket_plot.png)

*Le graphique ci-dessus montre la comparaison des temps d'exÃ©cution entre Pig et PySpark sur diffÃ©rents nombres de nÅ“uds. Il est clair que la performance varie en fonction du nombre de nÅ“uds et de la technologie utilisÃ©e.*

### Tendance gÃ©nÃ©rale
- ğŸ“ˆ L'augmentation du nombre de nÅ“uds rÃ©duit gÃ©nÃ©ralement le temps d'exÃ©cution pour les deux frameworks.

### Performance de Pig vs PySpark
- **Avec 2 nÅ“uds** : Pig est plus lent que PySpark de 17 minutes.
- **Avec 3 nÅ“uds** : Pig est en retard de 16 minutes par rapport Ã  PySpark.
- **Avec 4 nÅ“uds** : Pig est en retard de 9 minutes et 16 secondes par rapport Ã  PySpark.
- **Avec 5 nÅ“uds** : Pig est en avance de 1 minute et 26 secondes par rapport Ã  PySpark.

### EfficacitÃ© de l'ajout de nÅ“uds
- **Pour Pig** : En passant de 2 Ã  5 nÅ“uds, le temps d'exÃ©cution est rÃ©duit de 31 minutes. L'effet le plus significatif est observÃ© entre 2 et 3 nÅ“uds avec une rÃ©duction de 12 minutes.
- **Pour PySpark** : La rÃ©duction du temps d'exÃ©cution est plus rÃ©guliÃ¨re, passant de 1h 5min Ã  49min 39s avec l'ajout de nÅ“uds. La plus grande diffÃ©rence est observÃ©e entre 2 et 3 nÅ“uds avec une rÃ©duction de 11 minutes.

### ğŸ“ Points clÃ©s:
 
1. L'augmentation du nombre de nÅ“uds favorise une exÃ©cution plus rapide pour les deux frameworks. Cela met en Ã©vidence l'importance de la parallÃ©lisation dans les traitements de donnÃ©es.
2. Pig semble Ãªtre un peu plus variable dans ses amÃ©liorations avec l'ajout de nÅ“uds, alors que PySpark montre une tendance plus constante Ã  rÃ©duie le temps d'exÃ©cution.
3. IntÃ©ressant Ã  noter, avec 5 nÅ“uds, Pig parvient Ã  surpasser PySpark, mÃªme si ce n'est que d'une petite marge.

## ğŸ¯ Conclusion

Alors que PySpark domine en termes de performance dans la plupart des configurations, Pig semble avoir des moments oÃ¹ il peut Ãªtre compÃ©titif ou mÃªme surpasser PySpark, comme vu avec 5 nÅ“uds. Cela souligne l'importance de tester et d'optimiser les configurations en fonction des besoins spÃ©cifiques de chaque situation. Il est essentiel de rÃ©aliser des tests pratiques pour dÃ©terminer le meilleur framework Ã  utiliser selon le contexte