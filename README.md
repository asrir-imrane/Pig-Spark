# Hadoop/Spark Cluster on GCP with Pig and PySpark ğŸš€

Ce repo fournit des directives Ã©tape par Ã©tape et des scripts pour configurer et exÃ©cuter un cluster Hadoop/Spark sur Google Cloud Platform (GCP) en utilisant Pig et PySpark pour l'implÃ©mentation de PageRank.

## ğŸ“š Table of Contents
- [**Setting Up on GCP**](./setup/gcp_setup.md)
- [**Hadoop and Spark Installation & Configuration**](./setup/hadoop_spark_setup.md)
- [**Running PageRank with Pig and PySpark**](## ğŸš€ Running PageRank)


## ğŸš€ Running PageRank

### ğŸ– Pig

ğŸ“ **Directory**: `scripts/pig/`   
ğŸ”§ **Command**: Use `run_pagerank.sh` to initiate the PageRank computation.

| Nombre de nÅ“uds | Temps d'exÃ©cution | Dataproc Job ID |
|:---------------:|:-----------------:|:---------------:|
| 2               | 1h 5min           | `d197e9a75eb84e728f168ce07d1b2849` |
| 3               | 58min 8s          | `efb42eb6d08847768a6543a5ee8c7176` |
| 4               | 48min 31s         | `dcc9ddf87ec74685b960af7eef3763ea` |
| 5               | 41min 39s         | `2b2acb5c8bd7c41b4bb50232d9ecc0bd` |

### ğŸ”¥ PySpark

| Nombre de nÅ“uds | Temps d'exÃ©cution | Dataproc Job ID |
|:---------------:|:-----------------:|:---------------:|
| 2               | 1 h 22 min        | `8adfa467418740639f80428886007559` |
| 3               | 1 h 3 min         | `104ad0ee059d84dd7a108cb95c23387e1` |
| 4               | 58 min 15 s       | `4ecdd4e131e154d38b3e193019ed9cb09` |
| 5               | 59 min 13 s       | `d273d8af8251a474fa55d3a6cbbb3d87be` |

## ğŸ“Š Comparaison entre Pig et PySpark

![Comparaison Pig vs PySpark](./graph/trinket_plot.png)

## ğŸ’¡ Analyse

### Tendance gÃ©nÃ©rale
- ğŸ“ˆ L'augmentation du nombre de nÅ“uds rÃ©duit gÃ©nÃ©ralement le temps d'exÃ©cution pour les deux frameworks.

### Performance de Pig vs PySpark
- **Avec 2 nÅ“uds** : Pig est lÃ©gÃ¨rement plus rapide que PySpark.
- **Avec 3 nÅ“uds** : Pig a une avance notable sur PySpark.
- **Avec 4 nÅ“uds** : L'Ã©cart entre Pig et PySpark se rÃ©duit.
- **Avec 5 nÅ“uds** : PySpark rattrape presque Pig.

### EfficacitÃ© de l'ajout de nÅ“uds
- **Pour Pig** : Mise Ã  l'Ã©chelle efficace avec des nÅ“uds supplÃ©mentaires.
- **Pour PySpark** : AmÃ©lioration jusqu'Ã  4 nÅ“uds, plateau Ã  5 nÅ“uds.

### ğŸ“ Points clÃ©s:
1. Meilleure parallÃ©lisation avec plus de nÅ“uds.
2. Pig a une performance supÃ©rieure au dÃ©but.
3. PySpark rattrape Pig avec l'ajout de nÅ“uds.

## ğŸ¯ Conclusion:

Pig a une meilleure performance initiale, mais PySpark se rapproche avec plus de nÅ“uds. Il est crucial de tester ces frameworks avec diverses tÃ¢ches et paramÃ¨tres pour une Ã©valuation complÃ¨te.
